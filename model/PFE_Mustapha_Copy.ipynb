{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PFE_Mustapha_Copy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrAzhbA3q-7t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 907
        },
        "outputId": "fff64b97-9f26-4b6a-cb87-33a126ec6e2b"
      },
      "source": [
        "!pip install python-geohash\n",
        "!pip install geopandas\n",
        "!pip install polygon_geohasher\n",
        "!pip install geojson"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-geohash\n",
            "  Downloading https://files.pythonhosted.org/packages/9c/e2/1a3507af7c8f91f8a4975d651d4aeb6a846dfdf74713954186ade4205850/python-geohash-0.8.5.tar.gz\n",
            "Building wheels for collected packages: python-geohash\n",
            "  Building wheel for python-geohash (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-geohash: filename=python_geohash-0.8.5-cp36-cp36m-linux_x86_64.whl size=43665 sha256=253fc7ba99ff10e9eace0baddeb3503edfab04f40e24755b643605cbc8832dd5\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/64/5a/6a286481fc7c2a698d2f297d4c90af19946be430b23eba9a33\n",
            "Successfully built python-geohash\n",
            "Installing collected packages: python-geohash\n",
            "Successfully installed python-geohash-0.8.5\n",
            "Collecting geopandas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/dd/c0a6429cc7692efd5c99420c9df525c40f472b50705871a770449027e244/geopandas-0.8.0-py2.py3-none-any.whl (962kB)\n",
            "\u001b[K     |████████████████████████████████| 962kB 7.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.0.5)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.7.0)\n",
            "Collecting pyproj>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/c3/071e080230ac4b6c64f1a2e2f9161c9737a2bc7b683d2c90b024825000c0/pyproj-2.6.1.post1-cp36-cp36m-manylinux2010_x86_64.whl (10.9MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9MB 1.5MB/s \n",
            "\u001b[?25hCollecting fiona\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/20/4e63bc5c6e62df889297b382c3ccd4a7a488b00946aaaf81a118158c6f09/Fiona-1.8.13.post1-cp36-cp36m-manylinux1_x86_64.whl (14.7MB)\n",
            "\u001b[K     |████████████████████████████████| 14.7MB 209kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (1.18.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (2.8.1)\n",
            "Collecting click-plugins>=1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/da/824b92d9942f4e472702488857914bdd50f73021efea15b4cad9aca8ecef/click_plugins-1.1.1-py2.py3-none-any.whl\n",
            "Collecting cligj>=0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/e4/be/30a58b4b0733850280d01f8bd132591b4668ed5c7046761098d665ac2174/cligj-0.5.0-py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (1.12.0)\n",
            "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (7.1.2)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (19.3.0)\n",
            "Collecting munch\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Installing collected packages: pyproj, click-plugins, cligj, munch, fiona, geopandas\n",
            "Successfully installed click-plugins-1.1.1 cligj-0.5.0 fiona-1.8.13.post1 geopandas-0.8.0 munch-2.5.0 pyproj-2.6.1.post1\n",
            "Collecting polygon_geohasher\n",
            "  Downloading https://files.pythonhosted.org/packages/2b/55/51fc667ed4b660382fd77bb8c51da42fd231dda6c63e7ab7a27a7088a587/polygon-geohasher-0.0.1.tar.gz\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.6/dist-packages (from polygon_geohasher) (1.7.0)\n",
            "Requirement already satisfied: python-geohash in /usr/local/lib/python3.6/dist-packages (from polygon_geohasher) (0.8.5)\n",
            "Building wheels for collected packages: polygon-geohasher\n",
            "  Building wheel for polygon-geohasher (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for polygon-geohasher: filename=polygon_geohasher-0.0.1-cp36-none-any.whl size=4140 sha256=da3c01d90fe5a8a7cb69d9e8575ba8f87c78d17d93cae97dc78e2308ae1dd205\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f2/58/66d0dbbb82fac601389214faa50cb6f8ebcf494421dafdec52\n",
            "Successfully built polygon-geohasher\n",
            "Installing collected packages: polygon-geohasher\n",
            "Successfully installed polygon-geohasher-0.0.1\n",
            "Collecting geojson\n",
            "  Downloading https://files.pythonhosted.org/packages/e4/8d/9e28e9af95739e6d2d2f8d4bef0b3432da40b7c3588fbad4298c1be09e48/geojson-2.5.0-py2.py3-none-any.whl\n",
            "Installing collected packages: geojson\n",
            "Successfully installed geojson-2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFVe0iwuJbgV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "a76ffcd4-1239-46c5-c695-483d2a3c2214"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9BvK1IAYKGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import geohash\n",
        "import folium\n",
        "from polygon_geohasher.polygon_geohasher import geohash_to_polygon\n",
        "import geojson as json \n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import collections\n",
        "import statistics\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch.autograd import Variable\n",
        "_base32 = '0123456789bcdefghjkmnpqrstuvwxyz'\n",
        "_base32_map = {}\n",
        "for i in range(len(_base32)):\n",
        "\t_base32_map[_base32[i]] = i\n",
        "del i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVUn3Do6Cghk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.cuda = True\n",
        "        self.no_cuda = False\n",
        "        self.seed = 1\n",
        "        self.batch_size = 64\n",
        "        self.test_batch_size = 1000\n",
        "        self.epochs = 10\n",
        "        self.lr = 0.01\n",
        "        self.momentum = 0.5\n",
        "        self.log_interval = 10\n",
        "        self.img_size=9\n",
        "        self.num_filtre=64\n",
        "        self.size_filtre=5\n",
        "        self.kernel_maxpooling=2\n",
        "        self.stride_maxpooling=2\n",
        "        self.output_size_linear=64\n",
        "        self.hidden_size=16\n",
        "        self.output_size_linear_lstm=1\n",
        "        self.batsh_size=15\n",
        "        self.seq_len=8\n",
        "        self.date_rng = pd.to_datetime(pd.date_range(start='2018-01-01 00:00:00', end='2019-12-30 00:00:00', freq='H'))\n",
        "        self.number_of_zone_training=15\n",
        "\n",
        "args = Args()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlWzDB7DAQyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv('/content/drive/My Drive/bq-results-20200627-184642-1olk9ybv9nci/bq-results-20200627-184642-1olk9ybv9nci.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKyre8nL9vzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Weather=pd.read_excel('/content/drive/My Drive/Data/Weather_Data.xls')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gknd8EENHWqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Weather_cleaning(Weather) :\n",
        "  Weather['Time']=pd.to_datetime(Weather['Time'])\n",
        "  Weather['Time']=Weather['Time'].dt.strftime('%Y-%m-%d %H:00:00')\n",
        "  Data_Weather=pd.pivot_table(Weather, values=['T','U','Ff'], index=['Time'], aggfunc=np.mean)\n",
        "  Data_Weather['Time'] =Data_Weather.index\n",
        "  Data_Weather['Time']=pd.to_datetime(Data_Weather['Time'])\n",
        "  #Data_Weather['day_of_week'] = Data_Weather['Time'].dt.day_name()\n",
        "  Data_Weather['hour_of_day'] = Data_Weather['Time'].dt.hour\n",
        "  Data_Weather=Data_Weather.drop(['Time'],axis=1)\n",
        "  dfDummies = pd.get_dummies(Data_Weather['hour_of_day'], prefix = 'HOUR')\n",
        "  #dfDummies = pd.get_dummies(Data_Weather['day_of_week'], prefix = 'category')\n",
        "  Data_Weather=Data_Weather.drop(['hour_of_day'],axis=1)\n",
        "  #Data_Weather=Data_Weather.drop(['day_of_week'],axis=1)\n",
        "  #df=Data_Weather\n",
        "  df = pd.concat([Data_Weather, dfDummies], axis=1)\n",
        "  #df=df.reindex(['T','U','Ff','hour_of_day','category_Sunday','category_Monday','category_Thursday','category_Tuesday','category_Wednesday','category_Saturday'],axis=1)\n",
        "  df=df.rename(columns={\"T\": \"temperature_of_the_day\", \"U\": \"Humidity\",'Ff':'Wind_speed'})\n",
        "  df=df.drop([\"temperature_of_the_day\",\"Humidity\"],axis=1)\n",
        "  df = df.loc[(df.index >= str(args.date_rng.min())) & (df.index <= str(args.date_rng.max()))]\n",
        "  df.index = pd.DatetimeIndex(df.index)\n",
        "  df= df.reindex(args.date_rng, fill_value=0)\n",
        "  df=df.fillna(0 )\n",
        " \n",
        "  return df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaB_kSunBEra",
        "colab_type": "text"
      },
      "source": [
        "<h2>geohashFunction</h2>\n",
        "<h3> Description: </h3>\n",
        "La fonction <b>geohashFunction</b> reçoit en entrée les coordonnée d'un point et la résolution demandé et retourne le code géohash qui lui corréspond: \n",
        "<h3> Paramètres: </h3>\n",
        "<ul>\n",
        "  <li>X: latitude</li>\n",
        "  <li>Y: Longitude</li>\n",
        "  <li>resl: La résolution</li>\n",
        "</ul> \n",
        "<h3> Valeur retournée: </h3>\n",
        "<ul>\n",
        "   <li>Code géohash</li>\n",
        "</ul> \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gNnDPiSlqAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def geohashFunction(x,y):\n",
        "   return geohash.encode(x,y,6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brt9K-Dxzx3_",
        "colab_type": "text"
      },
      "source": [
        "<h2>decode_c2i</h2>\n",
        "<h3> Description: </h3>\n",
        "La fonction <b>decode_c2i</b> reçoit le hash code d'une \n",
        "zone et retourne les corrdénnées du centre de la zone.\n",
        "<h3> Paramètres: </h3>\n",
        "<ul>\n",
        "  <li>hashcode: le hashcode de la zone</li>\n",
        "</ul> \n",
        "<h3> Valeur retournée: </h3>\n",
        "<ul>\n",
        "   <li>tuple contenant les cordonnées</li>\n",
        "</ul> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KczOU0xalqTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_c2i(hashcode):\n",
        "\tlon = 0\n",
        "\tlat = 0\n",
        "\tbit_length = 0\n",
        "\tlat_length = 0\n",
        "\tlon_length = 0\n",
        "\tfor i in hashcode:\n",
        "\t\tt = _base32_map[i]\n",
        "\t\tif bit_length%2==0:\n",
        "\t\t\tlon = lon<<3\n",
        "\t\t\tlat = lat<<2\n",
        "\t\t\tlon += (t>>2)&4\n",
        "\t\t\tlat += (t>>2)&2\n",
        "\t\t\tlon += (t>>1)&2\n",
        "\t\t\tlat += (t>>1)&1\n",
        "\t\t\tlon += t&1\n",
        "\t\t\tlon_length+=3\n",
        "\t\t\tlat_length+=2\n",
        "\t\telse:\n",
        "\t\t\tlon = lon<<2\n",
        "\t\t\tlat = lat<<3\n",
        "\t\t\tlat += (t>>2)&4\n",
        "\t\t\tlon += (t>>2)&2\n",
        "\t\t\tlat += (t>>1)&2\n",
        "\t\t\tlon += (t>>1)&1\n",
        "\t\t\tlat += t&1\n",
        "\t\t\tlon_length+=2\n",
        "\t\t\tlat_length+=3\n",
        "\t\t\n",
        "\t\tbit_length+=5\n",
        "\t\n",
        "\treturn (lat,lon,lat_length,lon_length)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zcPujLAmFF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_i2c(lat,lon,lat_length,lon_length):\n",
        "\tprecision = int((lat_length+lon_length)/5)\n",
        "\tif lat_length < lon_length:\n",
        "\t\ta = lon\n",
        "\t\tb = lat\n",
        "\telse:\n",
        "\t\ta = lat\n",
        "\t\tb = lon\n",
        "\t\n",
        "\tboost = (0,1,4,5,16,17,20,21)\n",
        "\tret = ''\n",
        "\tfor i in range(precision):\n",
        "\t\tret+=_base32[(boost[a&7]+(boost[b&3]<<1))&0x1F]\n",
        "\t\tt = a>>3\n",
        "\t\ta = b>>2\n",
        "\t\tb = t\n",
        "\t\n",
        "\treturn ret[::-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl0KWzxKG9MY",
        "colab_type": "text"
      },
      "source": [
        "<h2>neighbors</h2>\n",
        "<h3> Description: </h3>\n",
        "La fonction <b>neighbors</b> reçoit en entrée le hashcode d'une zone et la taille du quartier et retourne une matrice de hashcodes.\n",
        "Au milieu de cette matrice il y a le hashcode en entrée et les autres cases de la matrice contient les hashcodes des zones voisines.\n",
        "La matrice est carré d'une taille (S x S).\n",
        "S doit être impair.\n",
        "<h3> Paramètres: </h3>\n",
        "<ul>\n",
        "  <li>hashcode: le hashcode de la zone</li>\n",
        "  <li>S: La taille du quartier</li>\n",
        "</ul> \n",
        "<h3> Valeur retournée: </h3>\n",
        "<ul>\n",
        "   <li>Une matrice hashcodes</li>\n",
        "</ul> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBTXz0Ykl5uE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def neighbors(hashcode,S):\n",
        "\n",
        "\t\n",
        "\t(lat,lon,lat_length,lon_length) = decode_c2i(hashcode)\n",
        "\tret = []\n",
        "\trang=S // 2\n",
        "\ttab=[]\n",
        "\ttab2=[]\n",
        "\ttab3=[]\n",
        "\n",
        "\tfor i in range (1,rang+1):\n",
        "\t\t\t\t\t\t\ttab.append(lat+rang+1-i)\n",
        "\t\t\t\t\t\t\ttab3.append(lat-i)       \n",
        "\tfor i in range(-rang,rang+1) :\n",
        "     \t\t\t\t\ttab2.append(lon+i)\n",
        " \n",
        "\tfor tlat in tab:\n",
        "          if not tlat >> lat_length:\n",
        "            for tlon in tab2:\n",
        "              ret.append(encode_i2c(tlat,tlon,lat_length,lon_length))\n",
        "        \n",
        "\ttlat = lat\n",
        "\tfor tlon in tab2:\n",
        "\t\tcode = encode_i2c(tlat,tlon,lat_length,lon_length) \n",
        "\t\tif code:\n",
        "\t\t\tret.append(code)\n",
        "   \n",
        "\tfor tlat in tab3:\n",
        "          if tlat >= 0:\n",
        "            for tlon in tab2:\n",
        "              ret.append(encode_i2c(tlat,tlon,lat_length,lon_length))\n",
        "          \n",
        "\treturn np.array(ret).reshape(S,S)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYFx7rYAXSv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_data(df) :\n",
        "  data=df.loc[(df['requested_date'] >= str(args.date_rng.min())) & (df['requested_date']<= str(args.date_rng.max()))]\n",
        "  data=df[['p_lat','p_lng','requested_date','coupon']]\n",
        "  data['geohash']=data.apply(lambda x: geohashFunction(x.p_lat, x.p_lng), axis=1)\n",
        "  data['geometry']=data['geohash'].apply(geohash_to_polygon)\n",
        "  data['requested_date']=pd.to_datetime(data['requested_date'])\n",
        "  data['requested_date']=data['requested_date'].dt.strftime('%Y-%m-%d %H:00:00')\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0_MvctDxm_E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "bf46abbe-0d1d-42e5-db31-1c927e8cd54e"
      },
      "source": [
        "dfcoupon=df[['requested_date','coupon']]\n",
        "dfcoupon=dfcoupon.dropna()\n",
        "dfcoupon['requested_date']=pd.to_datetime(dfcoupon['requested_date'])\n",
        "dfcoupon['requested_date']=dfcoupon['requested_date'].dt.strftime('%Y-%m-%d %H:00:00')\n",
        "pd.DataFrame({'requested_date':dfcoupon['requested_date'].unique()})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>requested_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-12-11 13:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-11-28 19:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-12-10 13:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-10-13 07:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-01-24 19:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8246</th>\n",
              "      <td>2019-11-17 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8247</th>\n",
              "      <td>2019-09-23 12:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8248</th>\n",
              "      <td>2019-08-12 13:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8249</th>\n",
              "      <td>2018-08-03 04:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8250</th>\n",
              "      <td>2019-02-09 23:00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8251 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           requested_date\n",
              "0     2019-12-11 13:00:00\n",
              "1     2019-11-28 19:00:00\n",
              "2     2019-12-10 13:00:00\n",
              "3     2019-10-13 07:00:00\n",
              "4     2019-01-24 19:00:00\n",
              "...                   ...\n",
              "8246  2019-11-17 00:00:00\n",
              "8247  2019-09-23 12:00:00\n",
              "8248  2019-08-12 13:00:00\n",
              "8249  2018-08-03 04:00:00\n",
              "8250  2019-02-09 23:00:00\n",
              "\n",
              "[8251 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrX-a1R-L29A",
        "colab_type": "text"
      },
      "source": [
        "<h2>seq_of_demand_zone</h2>\n",
        "<h3> Description: </h3>\n",
        "La fonction <b>seq_of_demand_zone</b> construit pour chaque timestemp une matrice contenant les valeurs de la demande pour chaqu'une des zones appartenant au voisinage de la zone en entrée, elle retourne donc l'état du quartier de la zone en entrée pour chaque timestemp.\n",
        "<h3> Paramètres: </h3>\n",
        "<ul>\n",
        "  <li>data: une dataframe contenant les données de la demande pour chaque zone.</li>\n",
        "  <li>zone: le géohash de la zone.</li>\n",
        "  <li>reshape:le nombre de timestemps.</li>\n",
        "</ul> \n",
        "<h3> Valeur retournée: </h3>\n",
        "<ul>\n",
        "   <li>Un tensor de quatre dimension, (nombre de timestemps, 1,S,S), ou S et la taille du quartier.</li>\n",
        "</ul> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8gxZZe8ATev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq_of_demand_zone(data,zone,reshape) :\n",
        "   x=[]     \n",
        "   Data=pd.crosstab(data['requested_date'],data['geohash'])\n",
        "   Data.index = pd.DatetimeIndex(Data.index)\n",
        "   Data= Data.reindex(args.date_rng, fill_value=0)\n",
        "   for zn in neighbors(zone,args.img_size).reshape(args.img_size*args.img_size,)  :\n",
        "     if zn not in Data.columns: \n",
        "        print(zn)\n",
        "        Data[str(zn)]= 0       \n",
        "   Data=Data[neighbors(zone,args.img_size).reshape(args.img_size*args.img_size,)]   \n",
        "   Data= Data.reindex(neighbors(zone,args.img_size).reshape(args.img_size*args.img_size,), axis=1)                     \n",
        "   for i in Data.index:\n",
        "        x.append(torch.from_numpy(np.array(Data.loc[i]).reshape(args.img_size,args.img_size)))                                                       \n",
        "   tensor= torch.stack(x)\n",
        "   return tensor.reshape(reshape,1,args.img_size,args.img_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0RxmmiWNBoR",
        "colab_type": "text"
      },
      "source": [
        "<h2>create_inout_sequences</h2>\n",
        "<h3> Description: </h3>\n",
        "La fonction <b>create_inout_sequences</b> reçoit en entrée un tensor de quatre dimension, (nombre de timestemps, 1,S,S), ou S et la taille d'un quartier (c'est le résultat de la fonction <b>seq_of_demand_zone</b> ) et la taille d'une séquence, elle construit des séquence d'une taille <b>tw</b> et retourne une list de tuplet, tel que chaque tuplet contient deux valeurs la première et un tensor de dimension trois (tw: taille de la séquence, S: la taille du quartier,S), la deuxième valeur contient la valeur de la demande de la zone en question dans le timestemp qui suit celle de la séquence construit.\n",
        "<h3> Paramètres: </h3>\n",
        "<ul>\n",
        "  <li>input_data: un tensor de dimension quatre.</li>\n",
        "  <li>tw: la taille de la séquence</li>\n",
        "</ul> \n",
        "<h3> Valeur retournée: </h3>\n",
        "<ul>\n",
        "   <li>une list de tuplet.</li>\n",
        "</ul> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYV0WJaGMhIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_inout_sequences(input_data, tw):\n",
        "    inout_seq = []\n",
        "    L = len(input_data)\n",
        "    for i in range(L-tw):\n",
        "        train_seq = input_data[i:i+tw]\n",
        "        train_label = input_data[i+tw:i+tw+1]\n",
        "        inout_seq.append((train_seq ,train_label[0][0][args.img_size//2][args.img_size//2]))\n",
        "    return inout_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mddl0NDQNHZE",
        "colab_type": "text"
      },
      "source": [
        "<h2>create_inout_sequences_extarnal_data</h2>\n",
        "<h3> Description: </h3>\n",
        "La fonction <b>create_inout_sequences_extarnal_data</b> reçoit en entrée les données du climat et la langueure de la séquence, elle retourne un tensor de dimension trois, contenant pour chaque séquence de données les données du climat qui lui corresponds.\n",
        "<h3> Paramètres: </h3>\n",
        "<ul>\n",
        "  <li>Une dataframe contenant les données du climat</li>\n",
        "  <li>La langueure de la séquence</li>\n",
        "</ul> \n",
        "<h3> Valeur retournée: </h3>\n",
        "<ul>\n",
        "   <li>Un tensor de dimmension trois, contenant les données de climat de chaque séquence.</li>\n",
        "\n",
        "</ul> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MVyurUeCS21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_inout_sequences_extarnal_data(input_data, tw):\n",
        "    inout_seq_external_data = []\n",
        "    L = len(input_data)\n",
        "    for i in range(L-tw):\n",
        "        train_seq_external_data = input_data[i:i+tw]\n",
        "        train_label = input_data[i+tw:i+tw+1]\n",
        "        inout_seq_external_data.append(train_seq_external_data.values)   \n",
        "    return torch.FloatTensor(inout_seq_external_data).view(L-tw ,args.seq_len,len(input_data.columns))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIzfgek3NNs9",
        "colab_type": "text"
      },
      "source": [
        "<h2>create_data_final</h2>\n",
        "<h3> Description: </h3>\n",
        "La fonction <b>create_data_final</b> combine les fonctions <b>create_inout_sequences</b> et <b>seq_of_demand_zone</b> pour créer les séquence de données pour entraîner le model.\n",
        "<h3> Paramètres: </h3>\n",
        "<ul>\n",
        "  <li>Une dataframe contenant les données de la demande</li>\n",
        "  <li>Le nombre de zone sur lesquelles on entraine le modèle</li>\n",
        "  <li>La langueure de la séquence</li>\n",
        "</ul> \n",
        "<h3> Valeur retournée: </h3>\n",
        "<ul>\n",
        "   <li>une list de tuplet.</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BYpUoc1DbSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_data_final(data,number_of_zone,sequence_len):\n",
        "  sequence_data=[]\n",
        "  Data=pd.crosstab(data['requested_date'],data['geohash'])\n",
        "  Data.index = pd.DatetimeIndex(Data.index)\n",
        "  Data=Data.reindex(Data.mean().sort_values(ascending=False).index, axis=1).iloc[:,0:args.number_of_zone_training]\n",
        "  for zone in Data.columns:\n",
        "    print(zone)\n",
        "    sequence_data.append(create_inout_sequences(seq_of_demand_zone(data,zone,len(args.date_rng)),sequence_len))\n",
        "  return sequence_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2O7qXNRbkPJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data= clean_data(df)  \n",
        "External_Feautre=Weather_cleaning(Weather)\n",
        "External_Feautre_sequence=create_inout_sequences_extarnal_data(External_Feautre,args.seq_len)\n",
        "seq=create_data_final(data,args.number_of_zone_training,args.seq_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN8dmHEDsHRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(External_Feautre_sequence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVkyqnotrtXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model DMLVST_DATA\n",
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "        \n",
        "    def forward(self,y_hats,y):\n",
        "        return torch.sum((y-y_hats)**2)\n",
        "        #return np.sqrt(torch.sum((y-y_hats)))\n",
        "        #return self.mse(yhat,y)\n",
        "\n",
        "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "if args.cuda:\n",
        "    torch.cuda.manual_seed(args.seed)\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
        "\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self,img_size,num_filtre,size_filtre,kernel_maxpooling,stride_maxpooling,output_size_linear):\n",
        "        super(CNN, self).__init__()\n",
        "        self.num_filtre=num_filtre\n",
        "        self.conv1 = nn.Conv2d(1,num_filtre, kernel_size=size_filtre)\n",
        "        self.conv_out=(img_size-size_filtre)+1\n",
        "        self.max_pool=nn.MaxPool2d( kernel_size=kernel_maxpooling,stride = stride_maxpooling)\n",
        "        self.max_pool_out=(self.conv_out-kernel_maxpooling)//stride_maxpooling+1\n",
        "        self.fc1 = nn.Linear(num_filtre*self.max_pool_out*self.max_pool_out,output_size_linear)\n",
        "    \n",
        "\n",
        "    def forward(self, x):\n",
        "        x=self.conv1(x)\n",
        "        x=self.max_pool(x)\n",
        "        x=F.relu(x)\n",
        "        x=F.dropout(x,0.3,training=True)\n",
        "        x=x.view(-1,self.num_filtre*self.max_pool_out*self.max_pool_out)\n",
        "        x=self.fc1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Combine(nn.Module):\n",
        "    def __init__(self,img_size,num_filtre,size_filtre,kernel_maxpooling,stride_maxpooling,output_size_linear,hidden_size,output_size_linear_lstm,batsh_size,seq_len):\n",
        "        super(Combine, self).__init__()\n",
        "        self.batsh_size=batsh_size\n",
        "        self.output_size_linear=output_size_linear\n",
        "        self.seq_len=seq_len\n",
        "        self.hidden_size=hidden_size\n",
        "        self.cnn = CNN(img_size,num_filtre,size_filtre,kernel_maxpooling,stride_maxpooling,output_size_linear)\n",
        "        #self.num_filtre=num_filtre\n",
        "        #self.conv1 = nn.Conv2d(1,num_filtre, kernel_size=size_filtre)\n",
        "        #self.conv_out=(img_size-size_filtre)+1\n",
        "        #self.max_pool=nn.MaxPool2d( kernel_size=kernel_maxpooling,stride = stride_maxpooling)\n",
        "        #self.max_pool_out=(self.conv_out-kernel_maxpooling)//stride_maxpooling+1\n",
        "        #self.fc1 = nn.Linear(num_filtre*self.max_pool_out*self.max_pool_out,output_size_linear)\n",
        "\n",
        "\n",
        "        self.lstm = nn.LSTM(output_size_linear+25,self.hidden_size)\n",
        "\n",
        "        self.linear = nn.Linear(self.hidden_size,output_size_linear_lstm)\n",
        "\n",
        "        self.hidden_cell = (torch.zeros(1,self.batsh_size,self.hidden_size),\n",
        "                            torch.zeros(1,self.batsh_size,self.hidden_size))\n",
        "    \n",
        "       \n",
        "    def forward(self, x,x_external_data):\n",
        "        c_out = self.cnn(x)\n",
        "        c_out=c_out.view(self.seq_len,self.batsh_size,self.output_size_linear )\n",
        "        ex=(x_external_data).view(args.seq_len,1,25)\n",
        "        data_external_for_reshape=[]\n",
        "        for i in range (args.number_of_zone_training) :\n",
        "             data_external_for_reshape.append(ex)\n",
        "        data_external_for_reshape=torch.cat(data_external_for_reshape).view(args.seq_len,args.number_of_zone_training,25)\n",
        "        #print(data_external_for_reshape)\n",
        "        input_lstm = torch.cat([c_out,data_external_for_reshape], 2)\n",
        "        #x=self.conv1(x)\n",
        "        #x=self.max_pool(x)\n",
        "        #x=F.relu(x)\n",
        "        #x=x.view(-1,self.num_filtre*self.max_pool_out*self.max_pool_out)\n",
        "        #c_out=F.normalize(self.fc1(x))\n",
        "        #input_lstm=c_out.view(self.seq_len,self.batsh_size,self.output_size_linear )\n",
        "        lstm_out, self.hidden_cell = self.lstm(input_lstm, self.hidden_cell)\n",
        "        predictions = self.linear(self.hidden_cell[0].view(self.batsh_size, -1))\n",
        "      \n",
        "        return  predictions \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0oPjFaejyCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cuda=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm5YVAXmAL6X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "299bc10d-599e-4b51-8d1e-f6ed33391b68"
      },
      "source": [
        "model=Combine(args.img_size,args.num_filtre,args.size_filtre,args.kernel_maxpooling,args.stride_maxpooling,args.output_size_linear,args.hidden_size,args.output_size_linear_lstm,args.batsh_size,args.seq_len)\n",
        "#torch.save(model.state_dict(),'model.pt')\n",
        "model.load_state_dict(torch.load('/content/drive/My Drive/Data/model.pt'))\n",
        "model=model.eval()\n",
        "model\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Combine(\n",
              "  (cnn): CNN(\n",
              "    (conv1): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1))\n",
              "    (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
              "  )\n",
              "  (lstm): LSTM(89, 16)\n",
              "  (linear): Linear(in_features=16, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPbyjqF4aKZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Combine(args.img_size,args.num_filtre,args.size_filtre,args.kernel_maxpooling,args.stride_maxpooling,args.output_size_linear,args.hidden_size,args.output_size_linear_lstm,args.batsh_size,args.seq_len)\n",
        "criterion =RMSELoss()\n",
        "#criterion = nn.MSELoss()\n",
        "#optimizer = optim.SGD(model.parameters(), lr=0.008 , momentum=args.momentum)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.00008 )\n",
        "\n",
        "for epoch in range (50) :\n",
        "   total_loss = []\n",
        "   model.train()\n",
        "   for i in range(0,16000)  :\n",
        "        input_data=[]\n",
        "        y=[]\n",
        "        for j in range(args.number_of_zone_training) :\n",
        "            input_data.append(seq[j][i][0])\n",
        "            y.append(seq[j][i][1])\n",
        "        if use_cuda and torch.cuda.is_available():   \n",
        "            x_train_external_data=External_Feautre_sequence[i]\n",
        "            x_train_zones_seq=torch.cat(input_data)\n",
        "        y_train_zones_seq=torch.from_numpy(np.array(y)).view(args.number_of_zone_training,-1) \n",
        "        model.hidden_cell[0].detach_()\n",
        "        model.hidden_cell[1].detach_()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x_train_zones_seq.float(),x_train_external_data.float())\n",
        "        loss  = criterion(output, y_train_zones_seq.float())#torch.sqrt(criterion(output, y_train_zones_seq.float()))\n",
        "        loss.backward(retain_graph=False)\n",
        "        optimizer.step()\n",
        "        total_loss.append(loss.item())\n",
        "    #*******************************Validation******************************************\n",
        "   pred=[]\n",
        "   total_loss_val = []\n",
        "   plotpred=[]\n",
        "   ploty=[]\n",
        "   model.eval()\n",
        "   for i in range(16000,17400)  :\n",
        "          input_data=[]\n",
        "          y=[]\n",
        "          for j in range(args.number_of_zone_training) : \n",
        "              input_data.append(seq[j][i][0])\n",
        "              y.append(seq[j][i][1])\n",
        "          if use_cuda and torch.cuda.is_available():  \n",
        "              x_train_external_data=External_Feautre_sequence[i]    \n",
        "              x_train_zones_seq=torch.cat(input_data)\n",
        "              y_train_zones_seq=torch.from_numpy(np.array(y)).view(args.number_of_zone_training,-1)\n",
        "          pred=model(x_train_zones_seq.float(),x_train_external_data.float())\n",
        "          plotpred.append(pred.detach().numpy().reshape(args.number_of_zone_training))\n",
        "          ploty.append(np.array(y))\n",
        "          loss  =criterion(pred, y_train_zones_seq.float())#torch.sqrt( criterion(pred, y_train_zones_seq.float()))\n",
        "          total_loss_val.append(loss.item())\n",
        "\n",
        "\n",
        "   #print('sequence : ',i,'Avrage sequences loss :',(sum(total_loss)/len(total_loss)), 'The loss of the last sequence :', loss.item())    \n",
        "   if epoch % 1 == 0:\n",
        "           print('epoch: ',epoch,'Avrage sequences loss :',(sum(total_loss)/len(total_loss)),epoch,'Avrage sequences loss validation :',(sum(total_loss_val)/len(total_loss_val)))     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeipO3lriDdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred=[]\n",
        "total_loss_val = []\n",
        "plotpred=[]\n",
        "ploty=[]\n",
        "model.eval()\n",
        "for i in range(16000,17400)  :\n",
        "          input_data=[]\n",
        "          y=[]\n",
        "          for j in range(args.number_of_zone_training) : \n",
        "              input_data.append(seq[j][i][0])\n",
        "              y.append(seq[j][i][1])\n",
        "          if use_cuda and torch.cuda.is_available():  \n",
        "              x_train_external_data=External_Feautre_sequence[i]    \n",
        "              x_train_zones_seq=torch.cat(input_data)\n",
        "              y_train_zones_seq=torch.from_numpy(np.array(y)).view(args.number_of_zone_training,-1)\n",
        "          pred=model(x_train_zones_seq.float(),x_train_external_data.float())\n",
        "          plotpred.append(pred.detach().numpy().reshape(args.number_of_zone_training))\n",
        "          ploty.append(np.array(y))\n",
        "          loss  =criterion(pred, y_train_zones_seq.float())#torch.sqrt( criterion(pred, y_train_zones_seq.float()))\n",
        "          total_loss_val.append(loss.item())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC1UXdEUrVUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ploty=pd.DataFrame(data=ploty)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4VA1TrYr2h-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotpred=pd.DataFrame(data=plotpred)\n",
        "plotpred[plotpred<1]=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3A3ub2mJ992",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "29bed0a2-2bb2-47ef-bba9-4f6d0b8fd88d"
      },
      "source": [
        "plotpred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.369356</td>\n",
              "      <td>2.787366</td>\n",
              "      <td>2.316286</td>\n",
              "      <td>2.669726</td>\n",
              "      <td>2.120655</td>\n",
              "      <td>1.288558</td>\n",
              "      <td>1.859458</td>\n",
              "      <td>2.338140</td>\n",
              "      <td>1.782753</td>\n",
              "      <td>1.520971</td>\n",
              "      <td>1.092058</td>\n",
              "      <td>1.83819</td>\n",
              "      <td>1.050179</td>\n",
              "      <td>1.388151</td>\n",
              "      <td>2.231528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.295418</td>\n",
              "      <td>1.850683</td>\n",
              "      <td>1.768195</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.133864</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.858488</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.091487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.073386</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.196344</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.321635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1395</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.014826</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1396</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1397</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1398</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.472413</td>\n",
              "      <td>1.180345</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.173906</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1399</th>\n",
              "      <td>2.407157</td>\n",
              "      <td>3.022595</td>\n",
              "      <td>3.163383</td>\n",
              "      <td>2.045436</td>\n",
              "      <td>2.250333</td>\n",
              "      <td>2.176916</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.667924</td>\n",
              "      <td>1.868904</td>\n",
              "      <td>1.214297</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.177037</td>\n",
              "      <td>3.819833</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1400 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1         2   ...        12        13        14\n",
              "0     4.369356  2.787366  2.316286  ...  1.050179  1.388151  2.231528\n",
              "1     3.295418  1.850683  1.768195  ...  0.000000  0.000000  1.091487\n",
              "2     0.000000  1.073386  0.000000  ...  0.000000  0.000000  1.321635\n",
              "3     0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "4     0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "...        ...       ...       ...  ...       ...       ...       ...\n",
              "1395  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "1396  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "1397  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "1398  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "1399  2.407157  3.022595  3.163383  ...  0.000000  1.177037  3.819833\n",
              "\n",
              "[1400 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCNS_Xs3KV96",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "1b789000-7e73-4ed8-d6e3-56066c0b1a98"
      },
      "source": [
        "ploty"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1395</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1396</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1397</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1398</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1399</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1400 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      0  1  2  3  4  5  6  7  8  9  10  11  12  13  14\n",
              "0     4  5  0  0  0  1  0  5  0  1   3   4   0   4   1\n",
              "1     1  0  2  1  0  0  0  0  0  0   3   1   1   0   3\n",
              "2     0  2  0  0  1  0  0  0  0  0   1   1   0   0   1\n",
              "3     2  0  0  0  0  0  0  0  0  0   1   0   0   0   0\n",
              "4     0  0  0  0  0  0  0  0  0  0   1   0   0   0   0\n",
              "...  .. .. .. .. .. .. .. .. .. ..  ..  ..  ..  ..  ..\n",
              "1395  4  5  0  0  0  2  0  0  0  0   0   2   1   1   2\n",
              "1396  1  0  4  1  1  3  0  1  0  0   0   4   0   0   0\n",
              "1397  2  1  0  0  0  2  2  1  0  0   0   0   0   0   1\n",
              "1398  2  2  0  0  1  3  0  0  0  0   1   0   2   0   3\n",
              "1399  0  0  0  1  4  3  2  0  0  2   0   1   0   0   0\n",
              "\n",
              "[1400 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP2vi8pPumOw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "2f33f41c-fa60-439d-c7e0-756e637b24de"
      },
      "source": [
        "for i in range(5):\n",
        "  df_all = pd.merge(ploty[i],plotpred[i] , how = 'outer', left_index=True, right_index=True)\n",
        "  df_all.plot(figsize=(200,40))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6e88fa5d841a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mdf_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mploty\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplotpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'outer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mdf_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUheDtSj93Sn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mapFolium (data,values):\n",
        "  Data=pd.crosstab(data['requested_date'],data['geohash'])\n",
        "  Data.index = pd.DatetimeIndex(Data.index)\n",
        "  Data=Data.reindex(Data.mean().sort_values(ascending=False).index, axis=1).iloc[:,0:args.number_of_zone_training]\n",
        "  dataFolium=pd.DataFrame({'geohash':Data.columns,'value':values})\n",
        "  dataFolium['geometry']= dataFolium['geohash'].apply(geohash_to_polygon)\n",
        "  dataFolium=gpd.GeoDataFrame(dataFolium)\n",
        "  dataFolium.crs = {'init': 'epsg:4326'}\n",
        "  lat, lng = (36.7525000,3.0419700)\n",
        "  m = folium.Map((lat, lng), zoom_start=12)\n",
        "  folium.Choropleth(geo_data=dataFolium, \n",
        "                  name='choropleth',\n",
        "                  data=dataFolium,\n",
        "                  columns=['geohash', 'value'],\n",
        "                  key_on='feature.properties.geohash',\n",
        "                  fill_color='YlGn',\n",
        "                  fill_opacity=0.7,\n",
        "                  line_opacity=0.2,\n",
        "                  legend_name='asdf').add_to(m)\n",
        "  return m                "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL3US5tD9-pY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "value=[val for val in plotpred.iloc[0,:]]\n",
        "datafol=data\n",
        "mapFolium(datafol,value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U37L3vL9I-OU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1fEI2d1APpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6hxUo2yb8Ji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch):\n",
        "    \n",
        "    for i in range(1128)  :\n",
        "        input_data=[]\n",
        "        y=[]\n",
        "        for j in range(number_of_zone_training) :\n",
        "            input_data.append(seq[j][i][0])\n",
        "            y.append(seq[j][i][1])\n",
        "        External_Feautre_sequence  \n",
        "        #x_train_external_feautre=External_Feautre_sequence[i]  \n",
        "        x_train_zones_seq=torch.cat(input_data)\n",
        "        y_train_zones_seq=torch.from_numpy(np.array(y)).view(number_of_zone_training,-1)\n",
        "        #x_train_zones_seq= torch.FloatTensor(x_train_zones_seq)\n",
        "       \n",
        "        #model.hidden_cell = (torch.zeros(1,number_of_zone_training, model.hidden_size),\n",
        "                       #torch.zeros(1, number_of_zone_training,model.hidden_size)) \n",
        "        model.hidden_cell[0].detach_()\n",
        "        model.hidden_cell[1].detach_()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x_train_zones_seq.float())\n",
        "        loss  = criterion(output, y_train_zones_seq.float())\n",
        "        loss.backward(retain_graph=False)\n",
        "        optimizer.step()\n",
        "        total_loss.append(loss.item())\n",
        "    print('sequence : ',i,'Avrage sequences loss :',(sum(total_loss)/len(total_loss)), 'The loss of the last sequence :', loss.item())    \n",
        "    if epoch % 3 == 0:\n",
        "           print('epoch: ',epoch,'Avrage sequences loss :',(sum(total_loss)/len(total_loss)), 'The loss of the last sequence :', loss.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtssmTgsmG5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPQ97V7EktJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4VPp9MdQGnP",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "<h3><b>Feature selection</b> </h3>\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vtb4hWlfsXyc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKx_A-yitQLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "External_Feautre=Weather_cleaning(Weather)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb0NFuzUtTuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhWStgddz19J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  Weather['Time']=pd.to_datetime(Weather['Time'])\n",
        "  Weather['Time']=Weather['Time'].dt.strftime('%Y-%m-%d %H:00:00')\n",
        "  Data_Weather=pd.pivot_table(Weather, values=['T','U','Ff'], index=['Time'], aggfunc=np.mean)\n",
        "  Data_Weather['Time'] =Data_Weather.index\n",
        "  Data_Weather['Time']=pd.to_datetime(Data_Weather['Time'])\n",
        "  Data_Weather['day_of_week'] = Data_Weather['Time'].dt.day_name()\n",
        "  Data_Weather['hour_of_day'] = Data_Weather['Time'].dt.hour\n",
        "  Data_Weather=Data_Weather.drop(['Time'],axis=1)\n",
        "  df=Data_Weather\n",
        "  #dfDummies = pd.get_dummies(Data_Weather['day_of_week'], prefix = 'category')\n",
        "  #Data_Weather=Data_Weather.drop(['day_of_week'],axis=1)\n",
        "  #df = pd.concat([Data_Weather, dfDummies], axis=1)\n",
        "  #df=df.reindex(['T','U','Ff','hour_of_day','category_Sunday','category_Monday','category_Thursday','category_Tuesday','category_Wednesday','category_Saturday'],axis=1)\n",
        "  #df=df.rename(columns={\"T\": \"temperature_of_the_day\", \"U\": \"Humidity\",'Ff':'Wind_speed'})\n",
        "  df = df.loc[(df.index >= str(args.date_rng.min())) & (df.index <= str(args.date_rng.max()))]\n",
        "  df.index = pd.DatetimeIndex(df.index)\n",
        "  df= df.reindex(args.date_rng, fill_value=0)\n",
        "  df=df.fillna(0)\n",
        "  \n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NezRAAcDHaKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "df['day_of_week']=df['day_of_week'].astype(str)\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(df['day_of_week'])\n",
        "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
        "df['day_of_week']=le.transform(df['day_of_week'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxBOGCyWK7GA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn import preprocessing\n",
        "from numpy import set_printoptions\n",
        "import matplotlib.pyplot as plt\n",
        "# load data\n",
        "X= df\n",
        "\n",
        "for zone in Data.columns:\n",
        "    Y = Data[zone]\n",
        "    # feature extraction\n",
        "    test = SelectKBest(score_func=f_classif, k=3)\n",
        "    fit = test.fit(X, Y)\n",
        "    # summarize scores\n",
        "    set_printoptions(precision=3)\n",
        "    #print(fit.scores_.argmax())\n",
        "   #features = fit.transform(X)\n",
        "    # summarize selected features\n",
        "    #features\n",
        "    plt.rcParams[\"figure.figsize\"] = (20,10)\n",
        "    plt.plot([0,1,2,3,4],fit.scores_)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lmRXdmIMet4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}